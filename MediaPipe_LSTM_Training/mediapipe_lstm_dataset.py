import os
import time
import random
import cv2
import gc
import redis
import torch
import mediapipe as mp
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from torch.cuda import empty_cache
from torch.optim import Adam
from torch.utils.data import Dataset, DataLoader
from torch.utils.data import random_split
from IPython.display import clear_output


redis_pool = redis.ConnectionPool(host='', port=6379, db=0, max_connections=4, password='')
mp_pose = mp.solutions.pose
attention_dot = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
draw_line = [[0, 1], [0, 4], [1, 2], [2, 3], [3, 7], [4, 5], [5, 6], [6, 8], [9, 10], [11, 13], [13, 15], [12, 14],
             [14, 16], [11, 12], [11, 23], [23, 24], [12, 24], [15, 21], [16, 22], [15, 17], [16, 18], [17, 19],
             [18, 20], [15, 19], [16, 20]]


def show_skeleton(video_path, interval, attention_dot, draw_line):
    xy_list_list, xy_list_list_flip = [], []
    cv2.destroyAllWindows()
    pose = mp_pose.Pose(static_image_mode=True, model_complexity=1, enable_segmentation=False, min_detection_confidence=0.3)
    cap = cv2.VideoCapture(video_path)
    if cap.isOpened():
        cnt = 0
        while True:
            ret, img = cap.read()
            if cnt == interval and ret == True:
                cnt = 0
                xy_list, xy_list_flip = [], []
                img = cv2.resize(img, (640, 480))
                results = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
                if not results.pose_landmarks:
                    continue
                idx = 0
                draw_line_dic = {}
                for x_and_y in results.pose_landmarks.landmark:
                    if idx in attention_dot:
                        xy_list.append(x_and_y.x)
                        xy_list.append(x_and_y.y)
                        xy_list_flip.append(1 - x_and_y.x)
                        xy_list_flip.append(x_and_y.y)
                        x, y = int(x_and_y.x*640), int(x_and_y.y*480)
                        draw_line_dic[idx] = [x, y]
                    idx += 1
                xy_list_list.append(xy_list)
                xy_list_list_flip.append(xy_list_flip)
                for line in draw_line:
                    x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]
                    x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]
                    img = cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                #cv2.imshow('Landmarks', img)
                cv2.waitKey(1)
            elif ret == False:
                break
            cnt += 1
    cap.release()
    cv2.destroyAllWindows()
    return xy_list_list + xy_list_list_flip


video_path = './train_video'
video_name_list = os.listdir(video_path)
dataset = []
length = 20
interval = 1
cls_num = len(video_name_list)

with redis.StrictRedis(connection_pool=redis_pool) as conn:
    conn.set('cls_num', cls_num)
    for x in range(cls_num):
        if video_name_list[x]:
            label = x
        skel_data = show_skeleton('{}/{}'.format(video_path, video_name_list[x]), interval, attention_dot, draw_line)
        for idx in range(0, len(skel_data), int(length/2)):
            seq_list = skel_data[idx:idx+length]
            if len(seq_list) == length:
                dataset.append({'key': label, 'value': seq_list})
        conn.hset('sign_label', label, video_name_list[x][:-4])
    random.shuffle(dataset)
    print(dataset)


if torch.cuda.is_available() == True:
    device = 'cuda:0'
    print('í˜„ì¬ ê°€ìƒí™˜ê²½ GPU ì‚¬ìš© ê°€ëŠ¥ìƒíƒœ')
else:
    device = 'cpu'
    print('GPU ì‚¬ìš© ë¶ˆê°€ëŠ¥ ìƒíƒœ')


class MyDataset(Dataset):
    def __init__(self, seq_list):
        self.X = []
        self.y = []
        for dic in seq_list:
            self.y.append(dic['key'])
            self.X.append(dic['value'])

    def __getitem__(self, index):
        data = self.X[index]
        label = self.y[index]
        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))

    def __len__(self):
        return len(self.X)


split_ratio = [0.8, 0.1, 0.1]
train_len = int(len(dataset) * split_ratio[0])
val_len = int(len(dataset) * split_ratio[1])
test_len = len(dataset) - train_len - val_len
print('{}, {}, {}'.format(train_len, val_len, test_len))

train_dataset = MyDataset(dataset)
train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])

train_loader = DataLoader(train_data, batch_size=8)
val_loader = DataLoader(valid_data, batch_size=8)
test_loader = DataLoader(test_data, batch_size=8)


class skeleton_LSTM(nn.Module):
    def __init__(self):
        super(skeleton_LSTM, self).__init__()
        self.lstm1 = nn.LSTM(input_size=50, hidden_size=128, num_layers=1, batch_first=True)
        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)
        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)
        self.dropout1 = nn.Dropout(0.1)
        self.lstm4 = nn.LSTM(input_size=512, hidden_size=256, num_layers=1, batch_first=True)
        self.lstm5 = nn.LSTM(input_size=256, hidden_size=128, num_layers=1, batch_first=True)
        self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)
        self.dropout2 = nn.Dropout(0.1)
        self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)
        self.fc = nn.Linear(32, cls_num)

    def forward(self, x) :
        x, _ = self.lstm1(x)
        x, _ = self.lstm2(x)
        x, _ = self.lstm3(x)
        x = self.dropout1(x)
        x, _ = self.lstm4(x)
        x, _ = self.lstm5(x)
        x, _ = self.lstm6(x)
        x = self.dropout2(x)
        x, _ = self.lstm7(x)
        x = self.fc(x[:, -1, :])
        return x


def init_model():
    plt.rc('font', size=10)
    global net, loss_fn, optim
    net = skeleton_LSTM().to(device)
    loss_fn = nn.CrossEntropyLoss()
    optim = Adam(net.parameters(), lr=0.0001)


# epoch ì¹´ìš´í„° ì´ˆê¸°í™”
def init_epoch():
    global epoch_cnt
    epoch_cnt = 0


def init_log():
    plt.rc('font', size=10)
    # ëª¨ë“  Logë¥¼ ì´ˆê¸°í™”
    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log
    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []
    time_log, log_stack = [], []


def record_train_log(_tloss, _tacc, _time):
    # Train Log ê¸°ë¡ìš©
    time_log.append(_time)
    tloss_log.append(_tloss)
    tacc_log.append(_tacc)
    iter_log.append(epoch_cnt)


def record_valid_log(_vloss, _vacc):
    # Validation Log ê¸°ë¡ìš©
    vloss_log.append(_vloss)
    vacc_log.append(_vacc)


def last(log_list):
    # ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ë§ˆì§€ë§‰ ìˆ«ìë¥¼ ë°˜í™˜(print_log í•¨ìˆ˜ì—ì„œ ì‚¬ìš©)
    if len(log_list) > 0:
        return log_list[len(log_list) - 1]
    else:
        return -1


def print_log():
    # í•™ìŠµ ì¶”ì´ ì¶œë ¥

    # ì†Œìˆ«ì  3ìë¦¬ ìˆ˜ê¹Œì§€ ì¡°ì ˆ
    train_loss = round(float(last(tloss_log)), 3)
    train_acc = round(float(last(tacc_log)), 3)
    val_loss = round(float(last(vloss_log)), 3)
    val_acc = round(float(last(vacc_log)), 3)
    time_spent = round(float(last(time_log)), 3)

    log_str = 'Epoch: {:3} | T_Loss {:5} | T_acc {:5} | V_Loss {:5} | V_acc. {:5} | \
ğŸ•’ {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)

    log_stack.append(log_str)  # í”„ë¦°íŠ¸ ì¤€ë¹„

    # í•™ìŠµ ì¶”ì´ ê·¸ë˜í”„ ì¶œë ¥
    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99)  # ê·¸ë˜í”„ ì‚¬ì´ì¦ˆ ì„¤ì •
    hist_fig.patch.set_facecolor('white')  # ê·¸ë˜í”„ ë°°ê²½ìƒ‰ ì„¤ì •

    # Loss Line êµ¬ì„±
    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')
    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')
    loss_axis.set_xlabel('epoch')
    loss_axis.set_ylabel('loss')

    # Acc. Line êµ¬ì„±
    acc_axis = loss_axis.twinx()
    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='red', marker='+')
    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='blue', marker='x')
    acc_axis.set_ylabel('accuracy')

    # ê·¸ë˜í”„ ì¶œë ¥
    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line  # ìœ„ì—ì„œ ì„ ì–¸í•œ pltì •ë³´ë“¤ í†µí•©
    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines])  # ìˆœì„œëŒ€ë¡œ ê·¸ë ¤ì£¼ê¸°
    loss_axis.grid()  # ê²©ì ì„¤ì •
    plt.title('Learning history until epoch {}'.format(last(iter_log)))
    plt.draw()

    # í…ìŠ¤íŠ¸ ë¡œê·¸ ì¶œë ¥
    clear_output(wait=True)
    plt.show()
    for idx in reversed(range(len(log_stack))):  # ë°˜ëŒ€ë¡œ sort ì‹œì¼œì„œ ì¶œë ¥
        print(log_stack[idx])


def clear_memory():
    if device != 'cpu':
        empty_cache()
    gc.collect()


def epoch(data_loader, mode='train'):
    global epoch_cnt

    # ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ ì´ˆê¸°í™”
    iter_loss, iter_acc, last_grad_performed = [], [], False

    # 1 iteration í•™ìŠµ ì•Œê³ ë¦¬ì¦˜(forë¬¸ì„ ë‚˜ì˜¤ë©´ 1 epoch ì™„ë£Œ)
    for _data, _label in data_loader:
        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)

        # 1. Feed-forward
        if mode == 'train':
            net.train()
        else:
            # í•™ìŠµë•Œë§Œ ì“°ì´ëŠ” Dropout, Batch Mormalizationì„ ë¯¸ì‚¬ìš©
            net.eval()

        result = net(data)  # 1 Batchì— ëŒ€í•œ ê²°ê³¼ê°€ ëª¨ë“  Classì— ëŒ€í•œ í™•ë¥ ê°’ìœ¼ë¡œ
        _, out = torch.max(result, 1)  # resultì—ì„œ ìµœëŒ€ í™•ë¥ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ class ë„ì¶œ

        # 2. Loss ê³„ì‚°
        loss = loss_fn(result, label)  # GT ì™€ Label ë¹„êµí•˜ì—¬ Loss ì‚°ì •
        iter_loss.append(loss.item())  # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Lossë¥¼ ê¸°ë¡

        # 3. ì—­ì „íŒŒ í•™ìŠµ í›„ Gradient Descent
        if mode == 'train':
            optim.zero_grad()  # ë¯¸ë¶„ì„ í†µí•´ ì–»ì€ ê¸°ìš¸ê¸°ë¥´ ì´ˆê¸°í™” for ë‹¤ìŒ epoch
            loss.backward()  # ì—­ì „íŒŒ í•™ìŠµ
            optim.step()  # Gradient Descent ìˆ˜í–‰
            last_grad_performed = True  # forë¬¸ ë‚˜ê°€ë©´ epoch ì¹´ìš´í„° += 1

        # 4. ì •í™•ë„ ê³„ì‚°
        acc_partial = (out == label).float().sum()  # GT == Label ì¸ ê°œìˆ˜
        acc_partial = acc_partial / len(label)  # ( TP / (TP + TN)) í•´ì„œ ì •í™•ë„ ì‚°ì¶œ
        iter_acc.append(acc_partial.item())  # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Acc. ê¸°ë¡

    # ì—­ì „íŒŒ í•™ìŠµ í›„ Epoch ì¹´ìš´í„° += 1
    if last_grad_performed:
        epoch_cnt += 1

    clear_memory()

    # lossì™€ accì˜ í‰ê· ê°’ for í•™ìŠµì¶”ì´ ê·¸ë˜í”„, ëª¨ë“  GTì™€ Labelê°’ for ì»¨í“¨ì „ ë§¤íŠ¸ë¦­ìŠ¤
    return np.average(iter_loss), np.average(iter_acc)


def epoch_not_finished():
    # ì—í­ì´ ëë‚¨ì„ ì•Œë¦¼
    return epoch_cnt < maximum_epoch


init_model()
init_epoch()
init_log()
maximum_epoch = 100

while epoch_not_finished():
    start_time = time.time()
    tloss, tacc = epoch(train_loader, mode='train')
    end_time = time.time()
    time_taken = end_time - start_time
    record_train_log(tloss, tacc, time_taken)
    with torch.no_grad():
        vloss, vacc = epoch(val_loader, mode='val')
        record_valid_log(vloss, vacc)
    print_log()

print('\n Training completed!')

with torch.no_grad():
    test_loss, test_acc = epoch(test_loader, mode='test')
    test_acc = round(test_acc, 4)
    test_loss = round(test_loss, 4)
    print('Test Acc.: {}'.format(test_acc))
    print('Test Loss: {}'.format(test_loss))

torch.save(net.state_dict(), 'model/homer.pt')
os.system('cp model/homer.pt /home/homer/model')

with redis.StrictRedis(connection_pool=redis_pool) as conn:
    conn.set('model_training', 'stop')



